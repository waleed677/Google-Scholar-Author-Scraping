# -*- coding: utf-8 -*-
import scrapy
import logging
from googlescholar.items import GooglescholarItem

class GoogleauthorSpider(scrapy.Spider):
	name = 'googleauthor'
	allowed_domains = ['scholar.google.com']
	#start_urls = ['https://scholar.google.com/citations?&user=jplQac8AAAAJ']
	start_urls = ['https://scholar.google.com/citations?view_op=search_authors&mauthors=machine+learning']
	# custom_settings = {
	# 	'DEPTH_LIMIT': 2
	# }
	
	# parse is function to extract and parsed data
	def parse(self, response):
		for author_sel in response.xpath('//div[@class="gsc_1usr"]'):
			link = author_sel.xpath(".//h3[@class='gs_ai_name']/a/@href").extract_first()
			url = response.urljoin(link)
			yield scrapy.Request(url,callback=self.parse_profile_content)
			
	def parse_profile_content(self,response):
		loop=0
		logging.info("parse_profile_content function")
		item = GooglescholarItem()
		item['name'] = response.xpath("//div[@id='gsc_prf_in']/text()").extract_first()
		item['email']= response.xpath("//div[@id='gsc_prf_ivh']/text()").extract_first()
		if response.xpath("//div[@class='gsc_prf_il']/text()[1]").extract_first() != "":
			position1 = response.xpath("//div[@class='gsc_prf_il']/text()[1]").extract_first()
			position2 = response.xpath("//div[@class='gsc_prf_il']/a/text()").extract_first()
			position3 = response.xpath("//div[@class='gsc_prf_il']/text()[2]").extract_first()
			positions = str(position1)+' '+str(position2)+' '+str(position3)
		item['position']=positions
		item['tags']= response.xpath("//div[@id='gsc_prf_int']/a/text()").extract()
		publication_data = response.xpath("//tr/td[@class='gsc_rsb_std']/text()").extract()
		item['citation']= publication_data[0]
		item['citation_2014']= publication_data[1]
		item['hindex']= publication_data[2]
		item['hindex_2014']= publication_data[3]
		item['iindex']= publication_data[4]
		item['iindex_2014']= publication_data[5]
		yield item
		
		yield scrapy.Request(response.url+'&cstart=0&pagesize=100',callback=self.publication_content)
		
		
	def publication_content(self,response):
		logging('in publication_content function')
		tmp = response.xpath('//tbody[@id="gsc_a_b"]/tr[@class="gsc_a_tr"]/td[@class="gsc_a_t"]/a/text()').extract()
		logging('in publication_content function 2')
			#items['pubs']=[]
		#n = len(tmp)
			# logging('total tiles',n)
			# for i in range(1,n+1):
			# 	logging('in loop')
			# 	pub = {}
			#  	pub['title']=response.xpath('//tbody[@id="gsc_a_b"]/tr[@class="gsc_a_tr"][%d]/td[@class="gsc_a_t"]/a/text()' % i).extract()
			# 	item['pubs'].append(pub)
			
			# yield item
			
			# if n == 100:
			# 	offset = 0; d = 0
			# 	idx = url.find('cstart=')
			# 	idx += 7
			# 	while url[idx].isdigit():
			# 		offset = offset*10 + int(url[idx])
			# 		idx += 1
			# 		d += 1
			# 	yield Request(url[:idx-d] + str(offset+100) + '&pagesize=100', self.publication_content)
			
			
			
		# publication title data 
		# for title in response.xpath("//tr[@class='gsc_a_tr']"):
		#     item['title'] = title.xpath("//td[@class='gsc_a_t']/a/text()").extract()
		
		

			# request = response.follow(user_link,callback=self.parse)
			# yield request
			
			# publicaton_data = response.xpath("//tr/td[@class='gsc_rsb_std']/text()").extract()
			#citations = publication_data[0]
			# citations_2014 =publication_data[1]
			# hindex = publication_data[2]
			# hindex_2014 = publication_data[3]
			# i10index = publication_data[4]
			# i10index_2014 = publication_data[5]

			# email= author_sel.xpath("//div[@class='gsc_1usr']//div[@class='gs_ai_eml']/text()").extract()
		  
			# if author_sel.xpath(".//div[@class='gs_ai_aff']/text()[1]").extract_first() != "":
			#     position1 = author_sel.xpath(".//div[@class='gs_ai_aff']/text()[1]").extract_first()
			#     position2 = author_sel.xpath(".//div[@class='gs_ai_aff']/span/text()").extract_first()
			#     position3 = author_sel.xpath(".//div[@class='gs_ai_aff']/text()[2]").extract_first()
			#     position = str(position1)+' '+str(position2)+' '+str(position3)
			#     logging.info("if mai aya hai")
			# position2 = author_sel.xpath(".//div[@class='gs_ai_aff']/span/text()").extract_first()
			# position3 = author_sel.xpath(".//div[@class='gs_ai_aff']/text()[2]").extract_first()
			# position = position1+' '+position2+' '+position3
			
			
		   
			
			# yield{
			#     'name':name,
			#     'link':user_link,
			#     'citations':citations,
			#     #'position' : position,
			#     'loop':loop
			#      }

		
		
		# next_page_url= response.xpath("//button[@class='gs_btnPR gs_in_ib gs_btn_half gs_btn_lsb gs_btn_srt gsc_pgn_pnx']/@onclick").extract_first().replace("\\x3d","=").replace("\\x26","?")
		# after_author = next_page_url.split("?")[5]
		# start = next_page_url.split("?")[6]
		# join_url = "&"+after_author+"&"+start
		# url = "https://scholar.google.com/citations?view_op=search_authors&mauthors=machine+learning"+join_url
		# logging.info("url is",url)
		# if start is not None:
		#     yield scrapy.Request(url)
			
		